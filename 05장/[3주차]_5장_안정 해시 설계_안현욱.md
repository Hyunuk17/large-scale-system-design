> **5장. 안정 해시 설계**

<details><summary><b>해시 키 재배치(rehash) 문제</b></summary>
  
  ---
  
  ### 해시 키 재배치(rehash) 문제
    
  **부하를 균등하게 나누는 방법**
  
  - **$N$개의 캐시 서버**에 부하를 균등하게 나누는 방법
  - **해시 함수** **: `serverIndex = hash(key) % N`**, $N$은 서버의 개수
  - **예제)**
      - **가정 : 4대의 서버 사용**
      - **계산 :** 특정 키가 보관된 서버를 알아내기 위한 **나머지(Modular) 연산**
   
        <img src="https://github.com/Hyunuk17/large-scale-system-design/assets/102630597/72c7c536-1fae-4a9e-aaa5-7e21ec09aa0a" width="400px"/>
        
        <img src="https://github.com/Hyunuk17/large-scale-system-design/assets/102630597/0b8feb9d-e019-4e73-8ebd-ab2578eaf22e" width="400px"/>
  
          - **서버 풀(Server Pool)의 크기가 고정**
          - **데이터 분포가 균등한 경우**
      - **가정 : 1번 서버에 장애 발생, 서버 풀의 크기 3**
          
        <img src="https://github.com/Hyunuk17/large-scale-system-design/assets/102630597/c411272d-6e24-4806-aa3b-8846fff5fa82" width="400px"/>
   
        <img src="https://github.com/Hyunuk17/large-scale-system-design/assets/102630597/e4eb634f-5d86-4073-bf66-292ce23c297a" width="400px"/>
  
          - **나머지 연산(%)의 결과가 달라짐**
          - **대규모 캐시 미스(Cache Miss) : 데이터가 없는 다른 서버에 접속**

  ---
</details>

<details>
  <summary><b>안정 해시</b></summary>
  
  ---
  
  ### 안정 해시
  
  **전통적 해시 테이블**
  
  - 슬롯의 수가 바뀌면 거의 대부분의 키를 재배치
  - **확장성에 취약**
  
  **안정 해시(Consistent Hash)**
  
  - **해시 테이블 크기가 조정될 때**, 평균적으로 오직 **$k/n$개의 키만 재배치**하는 기술
      - $k$ : 키의 개수
      - $n$ : 슬롯(slot)의 개수
  - 요청 또는 데이터를 **서버에 균등하게 나누기 위해** 일반적으로 사용
  - 나머지 연산(%, Modular)으로 대상을 탐색하지 않음
  
  **해시 공간과 해시 링**
  
  - **해시 함수 $f$**
      - SHA-1
      - 출력 값 범위 : $x_0, x_1, x_2 … x_n$
  - **해시 공간(Hash Space)**
      - 범위 : $0$ ~ $2^{160} -1$
      
    <img src="https://github.com/Hyunuk17/large-scale-system-design/assets/102630597/41ac1a2a-4d34-4cfa-bc67-eec72e1c37c1" width="400px"/>

      
  - **해시 링(Hash Ring)**
      - 해시 공간의 양쪽을 구부려 접어 원으로 만든 모양
      
    <img src="https://github.com/Hyunuk17/large-scale-system-design/assets/102630597/7b825c60-57f7-4284-b6de-f9f42c34c124" width="400px"/>

      
  
  **해시 서버**
  
  - **해시 함수 $f$**를 사용하여 **서버 IP**나 **이름**을 **해시 링 위에 대응** 시킨 것
      
    <img src="https://github.com/Hyunuk17/large-scale-system-design/assets/102630597/aa363299-a22d-455d-8ca0-5bebd4327c34" width="400px"/>

      
      - ex) 4개의 서버 $s_0, s_1, s_2, s_3$를 해시 링 위에 배치
  
  **해시 키**
  
  - **캐시할 키**를 **해시 링 위에 배치**
      
    <img src="https://github.com/Hyunuk17/large-scale-system-design/assets/102630597/f708d114-58a3-4094-a245-dcbb60b15e50" width="400px"/>

      
      - ex) 4개의 캐시할 키를 $k_0, k_1, k_2, k_3$를 해시 링 위에 배치
  
  **서버 조회**
  
  - 키의 위치로부터 **시계 방향으로 링을 탐색**하면서 **만나는 첫 번째 서버에 저장**
      
    <img src="https://github.com/Hyunuk17/large-scale-system-design/assets/102630597/08d54f24-c055-40f9-9163-4bdddfe67b25" width="400px"/>

      - ex) $k_1 → s_1, k_2 → s_2, k_3 → s_3, k_4 → s_4$
      
  
  **서버 추가**
  
  - 서버를 추가하더라도 **키 가운데 일부만 재배치**하면 됨
      
    <img src="https://github.com/Hyunuk17/large-scale-system-design/assets/102630597/88093e9b-6ed5-496a-bfac-57b35e35eaf4" width="400px"/>

      
      - ex) **$k_0 → s_4$(서버 추가, 키 재배치)** $→ s_0$, **다른 키들은 재배치되지 않음**
  
  **서버 제거**
  
  - 하나의 서버가 제거되면 **키 가운데 일부만 재배치**
      
    <img src="https://github.com/Hyunuk17/large-scale-system-design/assets/102630597/3d2c77ec-f75f-4162-8cf3-7e0093641781" width="400px"/>

      
      - ex) $s_1$**(삭제)**, $k_1 → s_2$**(재배치), 나머지 키에는 영향이 없음**
  
  **기본 구현법의 두 가지 문제**
  
  - **안정 해시 알고리즘**은 MIT에서 처음 제안됨
  - **기본 절차**
      - 서버와 키를 **균등 분포(Uniform Distribution) 해시 함수**로 해시 링에 배치
      - 키의 위치에서 **링을 시계 방향으로 탐색**하다 만나는 **최초의 서버에 키 저장**
  - **2가지 문제**
      - 1️⃣ **서버 추가/삭제 상황을 감안,** **파티션(Partition) 크기 균등 유지 불가능**
          - **파티션** : 인접한 서버 사이의 해시 공간
          - 각 서버의 파티션 크기가 너무 차이날 수 있음
          
        <img src="https://github.com/Hyunuk17/large-scale-system-design/assets/102630597/64f5be3e-b195-4569-9e58-cdd8ac3e2473" width="400px" />

          
          - ex) $s_1$**(삭제)**, $s_2$의 파티션이 다른 파티션 대비 **거의 2배**
      - 2️⃣ **키의 균등 분포(Uniform Distribution) 달성의 어려움**
          
        <img src="https://github.com/Hyunuk17/large-scale-system-design/assets/102630597/e3c05257-b773-49b9-b97c-d303faacd072" width="400px"/>

          
          - ex) $s_1$, $s_3$는 데이터를 거의 갖지 않음, **대부분의 키는 $s_2$에 보관**
          - **가상 노드(Virtual Node)** 또는 **복제(Replica)** 기법으로 해결
          
  
  **가상 노드(Virtual Node)**
  
  - **실제 노드 또는 서버를 가리키는 노드**
  - 하나의 서버는 **링 위에 여러 개의 가상 노드를 가질 수 있음**
      
    <img src="https://github.com/Hyunuk17/large-scale-system-design/assets/102630597/60dab80b-bcd3-4cbe-a2d6-ffb1a1ea6b9c" width="400px"/>

      
      - ex) $s_0, s_1$은 3개씩 가상 노드를 가지고 있음, $s_{0.0}, s_{0.1}, s_{0.2},\ \ s_{1.0}, s_{1.1}, s_{1.2}$
      - **각 서버는 여러 개 파티션을 관리**
  - **키의 위치에서 시계방향으로 링을 탐색, 만나는 최초의 가상 노드에 해당 키 저장**
      
    <img src="https://github.com/Hyunuk17/large-scale-system-design/assets/102630597/b94c9b36-aeff-46c7-80c2-94730f3ce0eb" width="400px"/>

      
      - ex) **$k_0$이 저장되는 서버** : 시계방향으로 처음만난 **$s_{1.1}$이 나타내는 서버 1**
  - **가상 노드의 개수를 늘리면 키의 분포는 점점 더 균등해짐**
      - **표준 편차(Standard Deviation)**가 작아져 데이터가 고르게 분포
      - ex) 100~200개 가상노드 사용 : 표준 편차 값은 평균의 5%~10%
      - 가상 노드 **데이터를 저장할 공간을 고려**하여 **타협적 결정(Trade-off)**
  
  **재배치할 키 결정**
  
  - 서버가 추가되거나 제거되면 **데이터 일부는 재배치**
  - **키를 재배치하는 범위 : 서버 추가**
      
    <img src="https://github.com/Hyunuk17/large-scale-system-design/assets/102630597/af0157de-1c10-4c8d-b4af-9c7c6df66dfd" width="400px"/>

      
      - ex) **$s_4$ 추가**, $s_3$ ~ $s_4$ 사이의 키들을 **$s_4$로 재배치**
  - **키를 재배치하는 범위 : 서버 삭제**
      
    <img src="https://github.com/Hyunuk17/large-scale-system-design/assets/102630597/de0db62f-c505-4114-95a8-da9166f984b5" width="400px"/>

      
      - ex) **$s_1$ 삭제**, 반시계 방향의 $s_0$ ~ $s_1$ 사이의 키 **$s_2$로 재배치**
      
  
  ---
</details>
<details>
  <summary><b>마치며</b></summary>
    
  ---
    
  ### 마치며
  
  **안정 해시의 이점**
  
  - 서버가 추가되거나 삭제될 때 **재배치되는 키의 수가 최소화**
  - **데이터가 보다 균등하게 분포하**게 되므로 **수평적 규모 확장성**을 달성하기 쉬움
  - **핫스팟(Hotspot) 키 문제**
      - **특정한 샤드(Shard)에 대한 접근**이 지나치게 빈번하면 **서버 과부하 문제**
      - 안정 해시는 **데이터를 좀 더 균등하게 분배**
  
  **이러한 기술들은 실제로 어디에 많이 쓰일까?**
  
  - **아마존 다이나모 데이터베이스(DynamoDB)의 파티셔닝 관련 컴포넌트**
      - Dynamo는 리더가 없는 복제시스템, 모든 노드에서 쓰기 요청처리 가능
      - 데이터를 여러 파티션에 분배, 사용할 때 안정 해시를 이용해 데이터 리밸런싱을 최소화
  - **아파치 카산드라(Apache Cassandra) 클러스터에서의 데이터 파티셔닝**
      - 데이터를 클러스터 내의 여러 노드에 분산
      - 파티셔닝 키를 해싱할 때 안정 해시를 사용
  - **디스코드(Discord)채팅 어플리케이션 - Elixir를 동시 사용자 오백만명으로 확장한 방법**
      - 새로운 유저가 들어왔을 때, 서버 클러스터 내에서 채널, 사용자 그룹을 특정 노드에 할당
      - 안정 해시를 사용하여 노드의 추가/삭제에 따른 리밸런싱을 최소화
  - **아카마이(Akamai) CDN**
      - 사용자의 요청을 전 세계에 분산된 캐시(컨텐츠) 서버에 효율적으로 라우팅
      - 서버가 추가/삭제 되더라도 요청 리밸런싱이 최소화 되도록 안정 해시를 사용
  - **매그래프(Meglev) 네트워크 로드 밸런서**
      - 구글이 만든 네트워크 로드밸런서로 트래픽을 균등하게 분산
  
  🍀**활용: Cassandra DB에서의 가상 노드**
  
  - **대용량의 데이터 시스템**을 관리하기 위해 개발된 DB
  - Cassandra DB는 가용성을 확보하기 위해 **여러 노드를 링 구조로 구성**
      
    <img src="https://github.com/Hyunuk17/large-scale-system-design/assets/102630597/084cbbb4-d6cc-4cf0-8976-c0f2ec1c9bdc" width="400px"/>

      
  - **어떤 노드에 저장할지 결정**하기 위해 **가상 노드(Virtual Node)** 개념 사용
      - 데이터를 균일하게 분산
      - 노드의 추가, 제거 시 데이터 이동, 복제, 리밸런싱에 높은 성능
      
    <img src="https://github.com/Hyunuk17/large-scale-system-design/assets/102630597/ae4bbb54-b59f-435f-9e86-ddfc84144086" width="400px" />

      
  
  ---
  
  **Reference**
  
  [안정 해시](https://jiwondev.tistory.com/299)
  
  [Cassandra](https://willseungh0.tistory.com/174)
  
  [Cassandra2](https://meetup.nhncloud.com/posts/58)

</details>
