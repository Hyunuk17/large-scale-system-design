> **13장. 검색어 자동완성 시스템**

<details>
  <summary><b>문제 이해 및 설계 범위 확정</b></summary>  
    
  ---
  
  ## 1단계: 문제 이해 및 설계 범위 확정
  
  ### 검색어 자동완성 시스템
  
  - **검색어 자동완성**
      - Autocomplete
      - Typeahead
      - Search-as-you-type
      - Incremental Search
  - 가장 많이 이용된 검색어 $N$개를 자동완성하여 출력
      
    <img src="https://github.com/user-attachments/assets/4da66c4f-1305-47e6-b505-5958ab48d832" width="400px"/>

      
  
  ### 요구사항 파악
  
  - **Q.** 사용자가 입력하는 단어가 자동완성될 검색어의 첫 부분인지 or 중간 부분도 가능한지?
  - **A.** 첫 부분으로 한정
  - **Q.** 몇 개의 자동완성 검색어가 표시되어야 하는지?
  - **A.** 5개
  - **Q.** 자동완성 검색어 5개를 고르는 기준은?
  - **A.** 질의 빈도에 따라 정해지는 검색어 인기 순위 기준
  - **Q.** 맞춤법 검사 기능도 제공해야 하는지?
  - **A.** 맞춤법 검사나 자동수정은 지원하지 않음
  - **Q.** 질의는 영어인지?
  - **A.** 시간이 있다면, 다국어 지원을 고려해도 됨
  - **Q.** 대문자나 특수 문자 처리를 해야하는지?
  - **A.** 모든 질의는 영어 소문자로 이루어진다고 가정
  - **Q.** 얼마나 많은 사용자를 지원해야 하는지?
  - **A.** 일간 능동 사용자(DAU) 기준, 천만명(10million)
  
  ### 요구사항 정**리**
  
  - **빠른 응답 속도**
      - 사용자가 검색어를 입력함에 따라 자동완성 검색어도 충분히 빨리 표시되어야 함
      - ex) Facebook 시스템 문서 : 응답속도는 100밀리초(ms) 이내, 그 이상은 이용에 불편
  - **연관성**
      - 자동완성되어 출력되는 검색어는 사용자가 **입력한 단어와 연관**된 것이어야 함
  - **정렬**
      - 계산 결과는 **인기도(Popularity)** 등의 **순위 모델(Ranking Model)에 의해 정렬**되어 있어야 함
  - **규모 확장성**
      - 시스템은 많은 트래픽을 감당할 수 있도록 **확장 가능**해야 함
  - **고가용성**
      - 시스템의 일부에 장애가 발생하거나, 느려지거나, 네트워크 문제가 생겨도 **시스템은 유지**
  
  ### 개략적 규모 추정
  
  - 일간 능동 사용자(**DAU**)는 **천만 명**으로 가정
  - 평균적으로 한 사용자는 **매일 $10$건의 검색**을 수행한다고 가정
  - 질의할 때마다 평균적으로 **$20$Byte의 데이터를 입력**한다고 가정
      - ASACII : 1문자 == 1Byte
      - 질의문은 평균적으로 $4$개 단어로 이루어진다고 가정
      - 각 단어는 평균적으로 $5$글자로 구성된다고 가정
      - 질의당 평균 20(4x5) 바이트
  - 검색창에 **글자를 입력할 때마다** 클라이언트는 검색어 자동완성 백엔드에 요청을 전송
      - 평균적으로 $1$회 검색당, $20$건 요청이 순차적으로 백엔드로 전달
      - 검색창에 ‘dinner’ 입력
          - `search?q=d`
          - `search?q=di`
          - `search?q=din`
          - `search?q=dinn`
          - `search?q=dinne`
          - `search?q=dinner`
  - **대략 초당 $24,000$건**의 질의(QPS)가 발생
      - 10,000,000(사용자) * 10(질의) / 20(글자) / 24(시간) / 3600(초)
  - **최대 QPS** :  $QPS*2 = 약 \ 48.000$
  - 질의 중 **$20\%$ 정도는 신규 검색어**라고 가정
      - 약 0.4GB : 10,000,000(사용자) * 10(질의) / 20(글자) * 20%
      - 매일 0.4GB의 신규 데이터가 시스템에 추가됨
  
  ---
  
  </details>
  
<details>
  <summary><b>개략적 설계안 제시 및 동의 구하기</b></summary>
  
  ---
  
  ## 2단계: 개략적 설계안 제시 및 동의 구하기
  
  ### 개략적 시스템 분류
  
  - **데이터 수집 서비스(Data Gathering Service)**
      - 사용자가 입력한 질의를 **실시간으로 수집**하는 시스템
      - 데이터가 많은 애플리케이션에 실시간 시스템은 바람직하지 않음
  - **질의 서비스(Query Service)**
      - **주어진 질의를 적용**하여 인기 검색어를 정렬하여 내놓는 서비스
  
  ### 데이터 수집 서비스
  
  - **빈도 테이블(Frequency Table)**
      
    <img src="https://github.com/user-attachments/assets/b094397a-dfc3-4949-b454-baeb5f86f260" width="400px"/>

      - 질의문과 사용 빈도를 저장
      - 사용자의 입력(**질의**)과 횟수(**사용 빈도**)를 저장
  
  ### 질의 서비스
  
  - **Query** : 질의문을 저장하는 필드
  - **Frequency** : 질의문이 사용된 빈도를 저장하는 필드
  - **예시) ‘tw’ 검색 시 연관 검색어 Top 5**
      
      
      - 빈도 테이블
      
    <img src="https://github.com/user-attachments/assets/73452b13-39fd-49f4-99b8-0eeac513ac40" width="400px"/>

      - 검색 결과
      
    <img src="https://github.com/user-attachments/assets/205b6f47-44e2-4152-89bc-2b9f371dc420" width="400px"/>

  - **SQL 질의**
      
      ```sql
      // 가장 많이 사용된 5개 검색어
      SELECT * 
      FROM frequency_table
      WHERE query LIKE 'prefix%'
      LIMIT 5
      ```
      
      - 데이터 양이 적은 경우에 나쁘지 않은 설계
      - 데이터가 아주 많아지면 **DB 병목 현상**이 일어날 수 있음
  
  ---
  
  </details>
<details>
  <summary><b>상세 설계</b></summary>
  
  ---
  
  ## 3단계: 상세 설계
  
  ### 검색어 자동완성 시스템의 주요 컴포넌트
  
  - 트라이(Trie) 자료구조
  - 데이터 수집 서비스(Data Gathering Service)
  - 질의 서비스(Query Service)
  - 규모 확장이 가능한 저장소
  - 트라이 연산
  
  ### 트라이 자료구조
  
  - 저장소로 관계형 데이터베이스(RDB)를 사용하는 것은 효율적이지 않음
  - **트라이(Trie)**
      - 접두어 트리(Prefix Tree)
      - re**trie**val, **문자열 탐색**에 중점을 둔 트리(Tree) 형태의 자료구조
  - **트라이 구조**
      
    <img src="https://github.com/user-attachments/assets/08c8b429-7ba4-42b9-a132-00e00fe7c05f" width="400px"/>

      - **Root 노드** : 빈 문자열을 의미
      - **각 노드** : 글자(Character) 하나 저장, 26개(알파벳)의 자식 노드를 가질 수 있음
      - 각 트리 노드는 하나의 단어 또는 접두어 문자열(Prefix String)을 나타냄
  - **빈도 정보를 포함하여 저장**
      
    <img src="https://github.com/user-attachments/assets/af0fd230-c52a-4d31-807a-c0288572b91e" width="400px"/>

      - Query : 찾고자 하는 단어, End Of Word
      - Frequency : 사용 빈도
  
  ### 트라이로 검색어 자동완성 구현
  
  - **용어**
      - $p$ : 접두어(Prefix)의 길이
      - $n$ : 트라이 안에 있는 노드 개수
      - $c$ : 주어진  노드의 자식 노드 개수
  - **가장 많이 사용된 질의어 $k$개 찾기**
      - 1️⃣ 입력된 접두어를 표현하는 노드를 찾기. $O(p)$
      - 2️⃣ 해당 노드부터 시작하는 하위 트리를 탐색하여 모든 유효 노드 찾기, $O(c)$
          - EndOfWord에 도달하여 하나의 문자열을 이루기까지의 모든 노드
      - 3️⃣ 유효 노드들을 정렬, 가장 인기있는 검색어 $k$개 찾기, $O(clogc)$
  - **시간복잡도**
      - 각 단계에 소요된 시간의 합
      - $O(p) + O(c) + O(clogc)$
  - 예제) $k=2$, 접두어 $‘be’$ 입력
      
    <img src="https://github.com/user-attachments/assets/289624de-2bc2-4104-907d-6a904ef07322" width="400px"/>

      - 접두어 노드 ‘be’를 찾음
      - 해당 노드부터 시작하는 하위 트리를 탐색, 모든 유효 노드를 찾음
      - 유효 노드를 정렬하여 2개($k$)를 선택 : `[best: 35]`, `[bet: 29]`
  - **문제점**
      - 최악의 경우 $k$개 결과를 얻기 위해 전체 트라이를 검색해야 할 수 있음
  - **해결방안**
      - 1️⃣ 접두어의 최대 길이를 제한
      - 2️⃣ 각 노드에 인기 검색어를 캐시
  
  ### 1️⃣ 접두어 최대 길이 제한
  
  - 사용자가 검색창에 **긴 검색어를 입력하는 일은 거의 없음**
  - **$p$값은 작은 정수라고 가정**해도 안전, ex) 50
  - 접두어 노드를 찾는 단계의 시간복잡도
      - $O(p) → O(작은 정수) →$ $O(1)$
  
  ### 2️⃣ 노드에 인기 검색어 캐시
  
  - **각 노드에 $k$개의 인기 검색어를 저장**
      - 전체 트라이를 검색하는 일을 방지
      - $k$는 작은 정수 : 5~10개 정도의 자동완성 제안이면 충분
  - **장점**
      - 인기 검색어를 질의하는 시간 복잡도를 상당히 낮출 수 있음
  - **단점**
      - 각 노드에 질의어를 저장할 공간이 많이 필요
      - 빠른 응답속도가 중요하다면, 저장공간을 희생할 만한 가치가 있음
  - **개선된 트라이 구조**
      
    <img src="https://github.com/user-attachments/assets/15050d0c-4779-42e0-9b47-5b30ce4c0240" width="400px"/>

      - 각 노드에 가장 인기있는 검색어 5가지를 저장
      - ex) be 노드 : `[best: 35]`, `[bet: 29]`, `[bee: 20]`, `[be: 15]`, `[beer: 10]`
  - **시간복잡도**
      - 최고 인기 검색어 질의의 결과를 캐싱하여 바로 찾을 수 있음
      - 질의의 시간복잡도, $O(1)$
  
  > **2가지 최적화 기법 적용**
  > 
  > 
  > 각 단계의 시간 복잡도가 $O(1)$
  > 
  > 최고 인기 검색어 $k$개를 찾는 전체 알고리즘의 시간복잡도도 $O(1)$  
  > 
  
  ### 데이터 수집 서비스
  
  - **지금까지 살펴본 설계안**
      - 사용자가 검색창에 타이핑 할 때마다 **실시간으로 데이터 수정,** 실용적이지 않음
      - **매일 수천만 건의 질의** : 매번 트라이를 갱신한다면, 서비스가 심각하게 느려질 것
      - **트라이를 자주 갱신할 필요 없음** : 일단 트라이 구성 이후, 인기 검색어가 잘 바뀌지 않음
  - **목적에 따른 설계**
      - 실시간 애플리케이션, ex) twitter : 제안되는 검색어를 항상 신선하게 유지할 필요 있음
      - 일반 애플리케이션, ex) Google : 제안되는 검색어가 그렇게 자주 바뀔 필요 없음
      - 트라이를 만들기 위한 데이터
          - 사용 목적이 달라도 데이터 수집 서비스의 토대는 같음
          - 보통 **데이터 분석 서비스(Analytics)**나 **로깅 서비스(Logging Service)**로부터 획득
  - **수정된 설계안**
      
    <img src="https://github.com/user-attachments/assets/8783e6d1-ea8b-4144-ad15-f297c9270654" width="400px"/>

      - 1️⃣ **데이터 분석 서비스 로그**
          
        <img src="https://github.com/user-attachments/assets/ab2f9161-b699-48f8-a5ef-75294227d178" width="400px"/>

          - 검색창에 입력된 질의에 관한 **원본 데이터 보관**
          - 새 데이터가 추가될 뿐, 수정은 이루어지지 않음
          - 로그 데이터는 인덱스를 걸지 않음
      - 2️⃣ **로그 취합 서버**
          - 데이터 분석 서비스의 로그는 보통 양이 엄청나게 많고, 형식이 제각각
          - 데이터를 잘 **취합(Aggregation)**하여 시스템이 쉽게 소비할 수 있도록 제공
          - 데이터 취합 주기
              - 대부분의 경우 : 일주일에 한 번 정도로 로그를 취합
              - 실시간 시스템의 경우 : 취합 주기를 보다 짧게 가져가야할 필요 있음
      - 3️⃣ **취합된 데이터**
          
        <img src="https://github.com/user-attachments/assets/26b02a61-ea5e-4ad5-85b2-4c6d77d6bc41" width="400px"/>

          - `query` : 질의된 문자열
          - `time` : 해당 주가 시작한 날짜
          - `frequency` : 해당 질의가 해당 주에 사용된 횟수의 합
      - 4️⃣ **작업 서버**
          - Worker
          - 주기적으로 **비동기적 작업(Job)을 실행**하는 서버 집합
              - 트라이 자료구조 생성
              - 트라이 데이터베이스에 저장
      - 5️⃣ **트라이 데이터베이스**
          - 지속성 저장소 : 데이터가 영구적으로 보관, 시스템이 종료되어도 유지됨
          - **문서 저장소(Document Store)**
              - 새 트라이를 매주 생성 : 주기적으로 트라이를 직렬화하여 DB에 저장
              - ex) MongoDB
          - **키-값 저장소(Key-Value Store)**
              
            <img src="https://github.com/user-attachments/assets/d5a65274-6a34-4816-928e-ad37d06f833c" width="400px"/>

              - 해시 테이블 형태로 변환하여 사용
                  - 트라이에 보관된 **모든 접두어를 해시 테이블 키로 변환**
                  - 각 트라이 노드에 보관된 **모든 데이터를 해시 테이블 값으로 변환**
                  - 각 트라이 노드는 `<Key, Value>` 쌍으로 변환됨
      - 6️⃣ **트라이 캐시**
          - **분산 캐시 시스템**을 통해 **트라이 데이터를 메모리에 유지**
              - 여러 대의 서버에 데이터를 분산 저장
              - 읽기 연산 성능을 높임
          - 매주 트라이 데이터베이스의 **스냅삿(Snapshot)**을 통해 갱신
  
  ### 질의 서비스
  
  - **설계안**
      
    <img src="https://github.com/user-attachments/assets/9a15eed5-d0fb-419f-842e-f60da1f1bdd9" width="400px"/>

      - 1️⃣ 검색 질의가 **로드밸런서**로 전송
      - 2️⃣ 로드밸런서는 해당 질의를 **API 서버**로 전송
      - 3️⃣ API 서버는 **트라이 캐시**에서 데이터를 가져와 **자동완성 검색어 제안 응답**을 구성
      - 4️⃣ 데이터가 트라이 캐시에 없는 경우, DB에서 데이터를 가져와 캐시에 저장
          - 다음에 같은 접두어(Prefix String)에 대한 질의 시 보관된 데이터 사용
          - **캐시 미스(Cache Miss)** : 캐시 서버의 메모리 부족, 캐시 서버 장애시 발생
  - **최적화 방안**
      - **AJAX 요청(Request)**
          - 보통의 웹 애플리케이션의 경우 AJAX 요청을 통해 자동완성된 검색어 목록을 호출
          - 요청을 보내고 받기 위해 페이지를 새로고침할 필요 없음(CSR)
      - **브라우저 캐싱(Browser Caching)**
          - 일반적으로 자동완성 검색에 제안 결과는 짧은 시간 안에 자주 바뀌지 않음
          - 한 번 제안된 검색어들을 브라우저 캐시에 넣어 후속 질의에서 사용
          - **ex) Google 검색 엔진**
              
            <img src="https://github.com/user-attachments/assets/a492aaed-b6e2-4dd6-943a-dc592b81416f" width="400px"/>

          - 응답 헤더(Request Header)에 제안된 검색어를 캐싱
          - **Cache-Control Header** :  HTTP에서 캐싱을 제어하기 위한 헤더
          - `private` : 공용 캐시에 저장하지 않음, 요청을 보낸 사용자의 캐시에만 보관될 수 있음
          - `max-age=3600` : 1시간 동안 캐싱 데이터 유효
      - **데이터 샘플링(Data Sampling)**
          - 대규모 시스템에서 모든 질의 결과를 로킹하면 CPU 자원과 저장공간을 너무 많이 소진
          - 샘플링을 통해 $N$개 요청 가운데 $1$개만 로깅
  
  ### 트라이 연산
  
  - **트라이 생성**
      - 작업 서버가 담당
      - 데이터 분석 서비스의 로그나 DB로부터 취합된 데이터를 이용
  - **트라이 갱신**
      - **매주 한 번 갱신**
          - 새로운 트라이 생성, 기존 트라이 대체
          - 주로 사용하는 방법
      - **트라이의 각 노드를 개별적으로 갱신**
          - 성능이 좋지 않음
          - 트라이가 작은 상황에서는 고려해볼 수 있는 방안
          
        <img src="https://github.com/user-attachments/assets/3d332693-37d7-4073-a881-a56268439b5c" width="400px"/>

          - 트라이 노드를 갱신할 때, 그 **모든 상위 노드(Ancestor)도 갱신**해야 함
          - 상위 노드에도 인기 검색어 질의 결과가 보관되기 때문
  - **검색어 삭제**
      - 위험한 질의어를 자동완성 결과에서 제거
          - ex) 혐오성이 짙거나 성적으로 노골적인 질의어 등
      - **트라이 캐시 앞에 필터 계층(Filter Layer)를 구축**

        <img src="https://github.com/user-attachments/assets/240b0b7d-5241-4a05-be64-6cd87a08de56" width="400px"/>

          - 필터 규칙에 따라 검색 결과를 자유롭게 변경
          - 부적절한 질의어가 반환되지 않도록 함
      - DB에서 해당 검색어를 물리적으로 삭제
          - 다음 업데이트 사이클에 비동기적으로 진행
  
  ### 저장소 규모 확장
  
  - **규모 확장성 문제**
      - 트라이의 크기가 한 서버에 넣기에 너무 큰 경우
  - **첫 글자를 기준으로 샤딩(Sharding)**
      - 영어만 지원한다고 가정 : 총 26개의 서버로 분할 가능
      - 3대 서버 사용 가정 : `a~i` 첫 번째 서버, `j~r` 두 번째 서버 저장, `s~z` 세 번째 서버 저장
      - **계층적 샤딩**
          - 문자의 Level 마다 샤딩
          - ex) `aa`, `ab`, `ac` … `az`
      - **균등하게 분배할 수 없음**
          - 특정 문자로 시작하는 단어의 수가 다름
          - ex) `c` 단어가 `x`단어보다 많음
  - **과거 질의 데이터의 패털을 분석하여 샤딩 (주로 사용)**
      
    <img src="https://github.com/user-attachments/assets/0318ff2e-8f8a-4f7f-aa98-fd5f692482e3" width="400px"/>

      - **검색어 대응 샤드 관리자(Shard Map Manager)**
          - 어떤 검색어가 어느 저장소 서버에 저장되는지에 대한 정보 관리
          - 검색어 양에 따라 분배, ex) `s` 샤드 1대와, `u~z` 샤드 1대
  
  ---
  

</details>
<details>
  <summary><b>마무리</b></summary>
  
  ---
  
  ## 마무리: 추가 고려사항
  
  ### **다국어 지원이 가능하도록 시스템 확장**
  
  - 비영어권 국가에서 사용하는 언어 지원
  - 트라이에 **유니코드(Unicode)** 데이터 저장
  - Unicode : 세상의 모든 문자 체계 지원를 지원하는 표준 인코딩 시스템
  
  ### **국가별로 다른 인기 검색어 순위 제공**
  
  - **국가별로 다른 트라이** 사용
  - 트라이를 **CDN에 저장**하여 응답속도를 높임
  
  ### 실시간으로 변하는 검색어 추이 반영
  
  - 새로운 뉴스 이벤트 등으로 특정 검색어의 인기가 갑자기 높아질 수 있음
  - **현재 설계안(적합하지 않음)**
      - 작업 서버가 매주 1번만 동작하여 시의 적절하게 트라이를 갱신할 수 없음
      - 때맞추어 서버가 실행된다 하더라도, 트라이를 구성하는 데 너무 많은 시간 소요
  - **개선 사항**
      - **샤딩(Sharding)**을 통해 작업 데이터의 양 감소
      - 순위 모델(Ranking Model)을 바꾸어 **최근 검색어에 보다 높은 가중치**  부여
      - **데이터가 스트림 형태**로 올 수 있음을 고려
          - 한 번에 모든 데이터를 동시에 사용할 수 없을 가능성 있음
          - 데이터 스트리밍 : 데이터가 지속적으로 생성된다는 의미
          - 스트림 프로세싱을 위한 시스템
              - 아파치 하둡 맵리듀스(Apache Hadoop MapReduce)
              - 아파치 스파크 스트리밍(Apcache Spark Streaming)
              - 아파치 스톰(Apache Storm)
              - 아파치 카프카(Apache Kafka)
          
  
  ---

</details>
